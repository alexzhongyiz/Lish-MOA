{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_targets_scored = pd.read_csv('train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1903):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=1903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature.shape: (23814, 904) test_features.shape (3982, 904)\n",
      "train_feature.shape: (23814, 909) test_features.shape (3982, 909)\n"
     ]
    }
   ],
   "source": [
    "# GENES\n",
    "n_comp = 28\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=1903).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "print(\"train_feature.shape:\", train_features.shape,\"test_features.shape\",test_features.shape)\n",
    "\n",
    "#CELLS\n",
    "n_comp = 5\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=1903).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "print(\"train_feature.shape:\", train_features.shape,\"test_features.shape\",test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_transformed.shape (27796, 901)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.4)\n",
    "data = train_features.append(test_features)\n",
    "\n",
    "feature_cols = train_features.columns.values[4:]\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "print(\"data_transformed.shape\",data_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_G-23</th>\n",
       "      <th>pca_G-24</th>\n",
       "      <th>pca_G-25</th>\n",
       "      <th>pca_G-26</th>\n",
       "      <th>pca_G-27</th>\n",
       "      <th>pca_C-0</th>\n",
       "      <th>pca_C-1</th>\n",
       "      <th>pca_C-2</th>\n",
       "      <th>pca_C-3</th>\n",
       "      <th>pca_C-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743672</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.756497</td>\n",
       "      <td>-1.093429</td>\n",
       "      <td>0.749532</td>\n",
       "      <td>-7.285008</td>\n",
       "      <td>0.608401</td>\n",
       "      <td>-0.007462</td>\n",
       "      <td>0.186788</td>\n",
       "      <td>-0.760827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605557</td>\n",
       "      <td>-0.905093</td>\n",
       "      <td>-0.756600</td>\n",
       "      <td>1.694579</td>\n",
       "      <td>3.023896</td>\n",
       "      <td>-7.417466</td>\n",
       "      <td>-0.756903</td>\n",
       "      <td>0.139662</td>\n",
       "      <td>-0.751076</td>\n",
       "      <td>-0.675731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597964</td>\n",
       "      <td>-1.571965</td>\n",
       "      <td>-1.768986</td>\n",
       "      <td>-1.278462</td>\n",
       "      <td>-2.976800</td>\n",
       "      <td>-2.247580</td>\n",
       "      <td>0.226875</td>\n",
       "      <td>0.088391</td>\n",
       "      <td>0.969065</td>\n",
       "      <td>-0.169469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>3.732154</td>\n",
       "      <td>-1.548930</td>\n",
       "      <td>-1.454501</td>\n",
       "      <td>-0.594539</td>\n",
       "      <td>-2.130195</td>\n",
       "      <td>13.943314</td>\n",
       "      <td>7.308940</td>\n",
       "      <td>0.512217</td>\n",
       "      <td>-3.353907</td>\n",
       "      <td>-1.337379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.322954</td>\n",
       "      <td>0.293573</td>\n",
       "      <td>-0.416163</td>\n",
       "      <td>1.286734</td>\n",
       "      <td>2.086231</td>\n",
       "      <td>-6.307752</td>\n",
       "      <td>0.262640</td>\n",
       "      <td>0.266405</td>\n",
       "      <td>0.634856</td>\n",
       "      <td>-0.196170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290860</td>\n",
       "      <td>-2.968704</td>\n",
       "      <td>0.421827</td>\n",
       "      <td>-0.843860</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>-6.398104</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.055015</td>\n",
       "      <td>-0.729866</td>\n",
       "      <td>-0.093763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.336899</td>\n",
       "      <td>0.627563</td>\n",
       "      <td>0.446241</td>\n",
       "      <td>-0.224986</td>\n",
       "      <td>-0.421141</td>\n",
       "      <td>-4.029873</td>\n",
       "      <td>-1.008948</td>\n",
       "      <td>1.117319</td>\n",
       "      <td>0.148991</td>\n",
       "      <td>-0.005460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360302</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.345062</td>\n",
       "      <td>-0.530562</td>\n",
       "      <td>-2.058057</td>\n",
       "      <td>-8.302736</td>\n",
       "      <td>0.451241</td>\n",
       "      <td>0.643414</td>\n",
       "      <td>-0.618859</td>\n",
       "      <td>0.647034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.854534</td>\n",
       "      <td>-1.225535</td>\n",
       "      <td>1.419350</td>\n",
       "      <td>-5.347429</td>\n",
       "      <td>-0.783404</td>\n",
       "      <td>-7.838803</td>\n",
       "      <td>0.176862</td>\n",
       "      <td>0.256411</td>\n",
       "      <td>0.313841</td>\n",
       "      <td>0.417585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608448</td>\n",
       "      <td>4.709620</td>\n",
       "      <td>-0.026005</td>\n",
       "      <td>-0.755906</td>\n",
       "      <td>0.100957</td>\n",
       "      <td>25.173208</td>\n",
       "      <td>3.487401</td>\n",
       "      <td>1.606593</td>\n",
       "      <td>1.237383</td>\n",
       "      <td>-0.653649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...     ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...  pca_G-23  pca_G-24  pca_G-25  pca_G-26  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...  0.743672  0.971888  0.756497 -1.093429   \n",
       "1      0.0604  1.0190  0.5207  ...  0.605557 -0.905093 -0.756600  1.694579   \n",
       "2     -0.0764 -0.0323  1.2390  ...  1.597964 -1.571965 -1.768986 -1.278462   \n",
       "3      0.5288  4.0620 -0.8095  ...  3.732154 -1.548930 -1.454501 -0.594539   \n",
       "4      0.6919  1.4180 -0.8244  ... -1.322954  0.293573 -0.416163  1.286734   \n",
       "...       ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ... -0.290860 -2.968704  0.421827 -0.843860   \n",
       "23810  0.9905 -0.7178  0.6621  ... -2.336899  0.627563  0.446241 -0.224986   \n",
       "23811 -0.7389  0.5505 -0.0159  ...  0.360302  0.001423  0.345062 -0.530562   \n",
       "23812  0.2044  0.8531 -0.0343  ... -1.854534 -1.225535  1.419350 -5.347429   \n",
       "23813  0.7952 -0.3611 -3.6750  ...  0.608448  4.709620 -0.026005 -0.755906   \n",
       "\n",
       "       pca_G-27    pca_C-0   pca_C-1   pca_C-2   pca_C-3   pca_C-4  \n",
       "0      0.749532  -7.285008  0.608401 -0.007462  0.186788 -0.760827  \n",
       "1      3.023896  -7.417466 -0.756903  0.139662 -0.751076 -0.675731  \n",
       "2     -2.976800  -2.247580  0.226875  0.088391  0.969065 -0.169469  \n",
       "3     -2.130195  13.943314  7.308940  0.512217 -3.353907 -1.337379  \n",
       "4      2.086231  -6.307752  0.262640  0.266405  0.634856 -0.196170  \n",
       "...         ...        ...       ...       ...       ...       ...  \n",
       "23809  0.304833  -6.398104  0.103700  0.055015 -0.729866 -0.093763  \n",
       "23810 -0.421141  -4.029873 -1.008948  1.117319  0.148991 -0.005460  \n",
       "23811 -2.058057  -8.302736  0.451241  0.643414 -0.618859  0.647034  \n",
       "23812 -0.783404  -7.838803  0.176862  0.256411  0.313841  0.417585  \n",
       "23813  0.100957  25.173208  3.487401  1.606593  1.237383 -0.653649  \n",
       "\n",
       "[23814 rows x 905 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed, columns=feature_cols[var_thresh.get_support()])], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed, columns=feature_cols[var_thresh.get_support()])], axis=1)\n",
    "\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_time cp_dose     g-0     g-1     g-2     g-3     g-4  \\\n",
       "0  id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "1  id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "\n",
       "      g-5     g-6  ...  tropomyosin_receptor_kinase_inhibitor  trpv_agonist  \\\n",
       "0 -1.0120 -1.0220  ...                                      0             0   \n",
       "1  0.5207  0.2341  ...                                      0             0   \n",
       "\n",
       "   trpv_antagonist  tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                0                  0                          0   \n",
       "1                0                  0                          0   \n",
       "\n",
       "   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                      0                0          0   \n",
       "1                                      0                0          0   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                           0              0  \n",
       "1                           0              0  \n",
       "\n",
       "[2 rows x 1110 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n",
    "\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 100 28 5 5\n"
     ]
    }
   ],
   "source": [
    "gen_cols = [c for c in feature_cols if 'g-' == c[:2]]\n",
    "cell_cols = [c for c in feature_cols if 'c-' == c[:2]]\n",
    "pca_gen_cols = [c for c in feature_cols if 'pca_G' == c[:5]]\n",
    "pca_cell_cols = [c for c in feature_cols if 'pca_C' == c[:5]]\n",
    "ohe_cols = [c for c in feature_cols if c not in gen_cols+cell_cols+pca_gen_cols+pca_cell_cols]\n",
    "print(len(gen_cols), len(cell_cols), len(pca_gen_cols), len(pca_cell_cols),len(ohe_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_gen_features, num_cell_features, num_genpca_features, num_cellpca_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.gen_batch_norm1 = nn.BatchNorm1d(num_gen_features)\n",
    "        self.gen_dropout1 = nn.Dropout(0.2)\n",
    "        self.gen_dense1 = nn.utils.weight_norm(nn.Linear(num_gen_features, hidden_size))\n",
    "        self.gen_batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.gen_dropout2 = nn.Dropout(0.3)\n",
    "        self.gen_dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.cell_batch_norm1 = nn.BatchNorm1d(num_cell_features)\n",
    "        self.cell_dropout1 = nn.Dropout(0.2)\n",
    "        self.cell_dense1 = nn.utils.weight_norm(nn.Linear(num_cell_features, int(hidden_size/2)))\n",
    "        self.cell_batch_norm2 = nn.BatchNorm1d(int(hidden_size/2))\n",
    "        self.cell_dropout2 = nn.Dropout(0.3)\n",
    "        self.cell_dense2 = nn.utils.weight_norm(nn.Linear(int(hidden_size/2), int(hidden_size/2)))\n",
    "        \n",
    "        self.genpca_batch_norm1 = nn.BatchNorm1d(num_genpca_features)\n",
    "        self.genpca_dropout1 = nn.Dropout(0.2)\n",
    "        self.genpca_dense1 = nn.utils.weight_norm(nn.Linear(num_genpca_features, num_genpca_features))\n",
    "        self.genpca_batch_norm2 = nn.BatchNorm1d(num_genpca_features)\n",
    "        self.genpca_dropout2 = nn.Dropout(0.3)\n",
    "        self.genpca_dense2 = nn.utils.weight_norm(nn.Linear(num_genpca_features, num_genpca_features))\n",
    "        \n",
    "        self.cellpca_batch_norm1 = nn.BatchNorm1d(num_cellpca_features)\n",
    "        self.cellpca_dropout1 = nn.Dropout(0.2)\n",
    "        self.cellpca_dense1 = nn.utils.weight_norm(nn.Linear(num_cellpca_features, num_cellpca_features))\n",
    "        self.cellpca_batch_norm2 = nn.BatchNorm1d(num_cellpca_features)\n",
    "        self.cellpca_dropout2 = nn.Dropout(0.3)\n",
    "        self.cellpca_dense2 = nn.utils.weight_norm(nn.Linear(num_cellpca_features, num_cellpca_features))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size + int(hidden_size/2) + num_genpca_features + num_cellpca_features)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size + int(hidden_size/2) + num_genpca_features + num_cellpca_features, num_targets))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, gen_x, cell_x, genpca_x, cellpca_x):\n",
    "#         print(cell_x.shape)\n",
    "        gen_x = self.gen_batch_norm1(gen_x)\n",
    "        gen_x = self.gen_dropout1(gen_x)\n",
    "        gen_x = F.relu(self.gen_dense1(gen_x))\n",
    "        gen_x = self.gen_batch_norm2(gen_x)\n",
    "        gen_x = self.gen_dropout2(gen_x)\n",
    "        gen_x = F.relu(self.gen_dense2(gen_x))\n",
    "        \n",
    "        cell_x = self.cell_batch_norm1(cell_x)\n",
    "        cell_x = self.cell_dropout1(cell_x)\n",
    "        cell_x = F.relu(self.cell_dense1(cell_x))\n",
    "        cell_x = self.cell_batch_norm2(cell_x)\n",
    "        cell_x = self.cell_dropout2(cell_x)\n",
    "        cell_x = F.relu(self.cell_dense2(cell_x))\n",
    "        \n",
    "        genpca_x = self.genpca_batch_norm1(genpca_x)\n",
    "        genpca_x = self.genpca_dropout1(genpca_x)\n",
    "        genpca_x = F.relu(self.genpca_dense1(genpca_x))\n",
    "        genpca_x = self.genpca_batch_norm2(genpca_x)\n",
    "        genpca_x = self.genpca_dropout2(genpca_x)\n",
    "        genpca_x = F.relu(self.genpca_dense2(genpca_x))\n",
    "        \n",
    "        cellpca_x = self.cellpca_batch_norm1(cellpca_x)\n",
    "        cellpca_x = self.cellpca_dropout1(cellpca_x)\n",
    "        cellpca_x = F.relu(self.cellpca_dense1(cellpca_x))\n",
    "        cellpca_x = self.cellpca_batch_norm2(cellpca_x)\n",
    "        cellpca_x = self.cellpca_dropout2(cellpca_x)\n",
    "        cellpca_x = F.relu(self.cellpca_dense2(cellpca_x))\n",
    "                \n",
    "        x = torch.cat((gen_x, cell_x, genpca_x, cellpca_x), dim=1)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, gen_features, cell_features, genpca_features, cellpca_features, targets):\n",
    "        self.gen_features = gen_features\n",
    "        self.cell_features = cell_features\n",
    "        self.genpca_features = genpca_features\n",
    "        self.cellpca_features = cellpca_features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.gen_features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'gen_x' : torch.tensor(self.gen_features[idx, :], dtype=torch.float),\n",
    "            'cell_x' : torch.tensor(self.cell_features[idx, :], dtype=torch.float),\n",
    "            'genpca_x' : torch.tensor(self.genpca_features[idx, :], dtype=torch.float),\n",
    "            'cellpca_x' : torch.tensor(self.cellpca_features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, gen_features, cell_features, genpca_features, cellpca_features):\n",
    "        self.gen_features = gen_features\n",
    "        self.cell_features = cell_features\n",
    "        self.genpca_features = genpca_features\n",
    "        self.cellpca_features = cellpca_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.gen_features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'gen_x' : torch.tensor(self.gen_features[idx, :], dtype=torch.float),\n",
    "            'cell_x' : torch.tensor(self.cell_features[idx, :], dtype=torch.float),  \n",
    "            'genpca_x' : torch.tensor(self.genpca_features[idx, :], dtype=torch.float),\n",
    "            'cellpca_x' : torch.tensor(self.cellpca_features[idx, :], dtype=torch.float)  \n",
    "        }\n",
    "        return dct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        gen_x, cell_x, genpca_x, cellpca_x, targets = data['gen_x'].to(device), data['cell_x'].to(device), data['genpca_x'].to(device), data['cellpca_x'].to(device), data['y'].to(device)\n",
    "        outputs = model(gen_x, cell_x, genpca_x, cellpca_x)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        gen_x, cell_x, genpca_x, cellpca_x, targets = data['gen_x'].to(device), data['cell_x'].to(device), data['genpca_x'].to(device), data['cellpca_x'].to(device), data['y'].to(device)\n",
    "        outputs = model(gen_x, cell_x, genpca_x, cellpca_x)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        gen_x, cell_x, genpca_x, cellpca_x = data['gen_x'].to(device), data['cell_x'].to(device), data['genpca_x'].to(device), data['cellpca_x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(gen_x, cell_x, genpca_x, cellpca_x)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    gen_x_train, cell_x_train, genpca_x_train, cellpca_x_train, y_train = train_df[gen_cols + ohe_cols].values, train_df[cell_cols + ohe_cols].values, train_df[pca_gen_cols + ohe_cols].values, train_df[pca_cell_cols + ohe_cols].values, train_df[target_cols].values\n",
    "    gen_x_valid, cell_x_valid, genpca_x_valid, cellpca_x_valid, y_valid = valid_df[gen_cols + ohe_cols].values, valid_df[cell_cols + ohe_cols].values, valid_df[pca_gen_cols + ohe_cols].values, valid_df[pca_cell_cols + ohe_cols].values, valid_df[target_cols].values\n",
    "    #     print(\"len target_cols\", len(target_cols), train_df[target_cols].shape, train_df[target_cols].reset_index(drop=True).shape)\n",
    "    #     print(\"shapes\", x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)\n",
    "\n",
    "    train_dataset = MoADataset(gen_x_train, cell_x_train, genpca_x_train, cellpca_x_train, y_train)\n",
    "    valid_dataset = MoADataset(gen_x_valid, cell_x_valid, genpca_x_valid, cellpca_x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "#     print('# of target cols', len(target_cols))\n",
    "    \n",
    "    model = Model(\n",
    "        num_gen_features=len(gen_cols + ohe_cols),\n",
    "        num_cell_features=len(cell_cols + ohe_cols),\n",
    "        num_genpca_features=len(pca_gen_cols + ohe_cols),\n",
    "        num_cellpca_features=len(pca_cell_cols + ohe_cols),\n",
    "        num_targets=len(target_cols),\n",
    "        hidden_size=hidden_size\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        elapse = time.time() - start\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss} {elapse:.2f} seconds\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    gen_x_test, cell_x_test, genpca_x_test, cellpca_x_test = test_[gen_cols + ohe_cols].values, test_[cell_cols + ohe_cols].values, test_[pca_gen_cols + ohe_cols].values, test_[pca_cell_cols + ohe_cols].values\n",
    "    testdataset = TestDataset(gen_x_test, cell_x_test, genpca_x_test, cellpca_x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_gen_features=len(gen_cols + ohe_cols),\n",
    "        num_cell_features=len(cell_cols + ohe_cols),\n",
    "        num_genpca_features=len(pca_gen_cols + ohe_cols),\n",
    "        num_cellpca_features=len(pca_cell_cols + ohe_cols),\n",
    "        num_targets=len(target_cols),\n",
    "        hidden_size=hidden_size\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self, num_gen_features, num_cell_features,num_targets, hidden_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.gen_batch_norm1 = nn.BatchNorm1d(num_gen_features)\n",
    "#         self.gen_dropout1 = nn.Dropout(0.2)\n",
    "#         self.gen_dense1 = nn.utils.weight_norm(nn.Linear(num_gen_features, hidden_size))\n",
    "#         self.gen_batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "#         self.gen_dropout2 = nn.Dropout(0.3)\n",
    "#         self.gen_dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "#         self.cell_batch_norm1 = nn.BatchNorm1d(num_cell_features)\n",
    "#         self.cell_dropout1 = nn.Dropout(0.2)\n",
    "#         self.cell_dense1 = nn.utils.weight_norm(nn.Linear(num_cell_features, int(hidden_size/2)))\n",
    "#         self.cell_batch_norm2 = nn.BatchNorm1d(int(hidden_size/2))\n",
    "#         self.cell_dropout2 = nn.Dropout(0.3)\n",
    "#         self.cell_dense2 = nn.utils.weight_norm(nn.Linear(int(hidden_size/2), int(hidden_size/2)))\n",
    "        \n",
    "#         self.batch_norm3 = nn.BatchNorm1d(hidden_size + int(hidden_size/2) )\n",
    "#         self.dropout3 = nn.Dropout(0.25)\n",
    "#         self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size + int(hidden_size/2), num_targets))\n",
    "        \n",
    "        \n",
    "    \n",
    "#     def forward(self, gen_x, cell_x):\n",
    "# #         print(cell_x.shape)\n",
    "#         gen_x = self.gen_batch_norm1(gen_x)\n",
    "#         gen_x = self.gen_dropout1(gen_x)\n",
    "#         gen_x = F.relu(self.gen_dense1(gen_x))\n",
    "#         gen_x = self.gen_batch_norm2(gen_x)\n",
    "#         gen_x = self.gen_dropout2(gen_x)\n",
    "#         gen_x = F.relu(self.gen_dense2(gen_x))\n",
    "\n",
    "#         cell_x = self.cell_batch_norm1(cell_x)\n",
    "#         cell_x = self.cell_dropout1(cell_x)\n",
    "#         cell_x = F.relu(self.cell_dense1(cell_x))\n",
    "#         cell_x = self.cell_batch_norm2(cell_x)\n",
    "#         cell_x = self.cell_dropout2(cell_x)\n",
    "#         cell_x = F.relu(self.cell_dense2(cell_x))\n",
    "                \n",
    "#         x = torch.cat((gen_x,cell_x),dim=1)\n",
    "#         x = self.batch_norm3(x)\n",
    "#         x = self.dropout3(x)\n",
    "#         x = self.dense3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.47592380550392227\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.023442984223365784 3.70 seconds\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.0208129358484226\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.018651681020855904 2.99 seconds\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.018767618726254726\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01792339824140072 3.11 seconds\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01777006941689115\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017474866695702074 3.12 seconds\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.017480886889761\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017412602864205838 3.01 seconds\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017356891305420268\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01748192425817251 3.11 seconds\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017375252374327507\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017758790627121924 3.07 seconds\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01740945389076155\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017338837757706643 2.91 seconds\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017430662659003216\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.0172028911113739 3.11 seconds\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017417751341348604\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017304080836474896 3.10 seconds\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017404507794955962\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017182074226438998 3.15 seconds\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017415364513642527\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017192069813609122 3.12 seconds\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017324937102036413\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01723851677030325 3.07 seconds\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01722569672428832\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01699531402438879 3.16 seconds\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017106608449652488\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017045026496052742 3.08 seconds\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.016996631930981363\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016798948012292383 3.11 seconds\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.016829208173111183\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016776805371046068 3.12 seconds\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.016685335542119685\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016550888270139695 3.17 seconds\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.016430038800399727\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016444318853318693 3.09 seconds\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016221246023212565\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016347848288714887 3.11 seconds\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.015987611977624244\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01618629101663828 3.12 seconds\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.015675340101224223\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016096022501587866 3.17 seconds\n",
      "FOLD: 0, EPOCH: 22, train_loss: nan\n",
      "FOLD: 0, EPOCH: 22, valid_loss: nan 3.11 seconds\n",
      "FOLD: 0, EPOCH: 23, train_loss: nan\n",
      "FOLD: 0, EPOCH: 23, valid_loss: nan 3.05 seconds\n",
      "FOLD: 0, EPOCH: 24, train_loss: nan\n",
      "FOLD: 0, EPOCH: 24, valid_loss: nan 3.16 seconds\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.4747247566678086\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.028103186339139937 3.01 seconds\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.020914110842914807\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.019127743691205977 3.13 seconds\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.018735168495399204\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.017836554534733297 3.16 seconds\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.017818484639077366\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017470429874956606 2.99 seconds\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.017442616044866795\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017363882698118685 3.12 seconds\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017349155461352295\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017315478399395942 3.13 seconds\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017358457872352632\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017318266108632088 3.17 seconds\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017439035787468866\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017447604164481163 3.12 seconds\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017424293141178535\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017240743897855283 3.10 seconds\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017432332862498\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01728180132806301 3.15 seconds\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017451749157895442\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017353066615760325 3.18 seconds\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017361029830514168\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017296718768775463 3.04 seconds\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017325040985684412\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017269977033138276 3.12 seconds\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017278156705758198\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017098779045045375 3.17 seconds\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017105447210776968\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016938703395426274 3.12 seconds\n",
      "FOLD: 1, EPOCH: 15, train_loss: nan\n",
      "FOLD: 1, EPOCH: 15, valid_loss: nan 3.04 seconds\n",
      "FOLD: 1, EPOCH: 16, train_loss: nan\n",
      "FOLD: 1, EPOCH: 16, valid_loss: nan 3.10 seconds\n",
      "FOLD: 1, EPOCH: 17, train_loss: nan\n",
      "FOLD: 1, EPOCH: 17, valid_loss: nan 3.12 seconds\n",
      "FOLD: 1, EPOCH: 18, train_loss: nan\n",
      "FOLD: 1, EPOCH: 18, valid_loss: nan 3.05 seconds\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.4746474665494598\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.025545916333794595 3.05 seconds\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02115057746493289\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01875421904027462 3.12 seconds\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.018655480341795757\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.017963435649871826 3.18 seconds\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.01782880561920453\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01747297912836075 3.11 seconds\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.017527285545152062\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017510242462158203 3.11 seconds\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.0173605703273598\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017326575964689256 3.18 seconds\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017339918223925593\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017519795671105384 3.14 seconds\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.0174172540024227\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01744495801627636 3.11 seconds\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017439639670964405\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017629111036658287 3.12 seconds\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01743822734245435\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017344953119754793 3.15 seconds\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017386287032645577\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01728439301252365 3.15 seconds\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01734379761960028\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01720835566520691 3.13 seconds\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017360360171569854\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017340752333402633 3.18 seconds\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.01728145708488364\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01710429199039936 3.12 seconds\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01713971962176618\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017078239768743515 3.10 seconds\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01700854774716557\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01688442215323448 3.12 seconds\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01679741226288737\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016706660352647305 3.19 seconds\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.016633439847097104\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016655476801097392 3.10 seconds\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01641714259297872\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01638428270816803 3.13 seconds\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016164194412377417\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016325935535132886 3.13 seconds\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.01588488206089962\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016239250265061855 3.16 seconds\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.015618689377240988\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016105330362915993 3.13 seconds\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.015303359519006039\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01603619795292616 3.11 seconds\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.015074840290661978\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01599276788532734 3.17 seconds\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.014990872507091283\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01600396115332842 3.12 seconds\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.47530348060437205\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.024782742410898208 3.00 seconds\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02126724513716438\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01910556621849537 3.10 seconds\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.018723708178315843\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01979254111647606 3.16 seconds\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.017873713683311632\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017635162696242334 3.11 seconds\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.017467055761185634\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017481193915009498 3.13 seconds\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01733665048543896\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017507009133696558 3.19 seconds\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017327039274482096\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01783698543906212 3.13 seconds\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01740938824835886\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017620134577155114 3.03 seconds\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017387410847558862\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017711324468255043 3.03 seconds\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017405955482046216\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017422647699713707 3.18 seconds\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017306749449193883\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017419879883527757 3.12 seconds\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017289422103995773\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.0173667062073946 3.04 seconds\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017259744312740914\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.0173218709230423 3.12 seconds\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017188692345049512\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017253856174647808 3.20 seconds\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01707287379825602\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01715042769908905 3.13 seconds\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.016982705237305894\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017006011791527272 3.13 seconds\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01678747894103024\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016826867870986462 3.16 seconds\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.016602925157972744\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01674234203994274 3.10 seconds\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.01642377411021667\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016630229875445365 3.13 seconds\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016142790104408247\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01651109978556633 3.11 seconds\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.015877108311369306\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01629595000296831 3.18 seconds\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01561273818797603\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016211130060255527 3.06 seconds\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015363332885159117\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01612385328859091 2.94 seconds\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.01513141504533234\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016081347800791262 3.18 seconds\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.01503782614203943\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016075586453080177 3.13 seconds\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.4753894132314896\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.02458381436765194 3.07 seconds\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.020893961254532644\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01860284451395273 3.13 seconds\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.018672261703886143\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.017605380341410636 3.11 seconds\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.017763572751360687\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017641950771212576 3.13 seconds\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.017434992244606522\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017272676192224026 3.15 seconds\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017337952632786466\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.0171351745352149 3.14 seconds\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01736570667906278\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01717665623873472 3.23 seconds\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017447242234535768\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017345792464911938 3.17 seconds\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017434672332134377\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017005909904837607 3.13 seconds\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017438350859902748\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01696437943726778 3.18 seconds\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017458356505095148\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017142863720655443 3.12 seconds\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01741436322783532\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017272179536521434 3.13 seconds\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01734229979314366\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017166974768042565 3.13 seconds\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017250689538512505\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017023086622357367 3.12 seconds\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017104915450928973\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01686153922230005 3.08 seconds\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01701691513564311\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016676626801490783 3.03 seconds\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.016870611423284422\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01654967460781336 3.19 seconds\n",
      "FOLD: 4, EPOCH: 17, train_loss: nan\n",
      "FOLD: 4, EPOCH: 17, valid_loss: nan 3.10 seconds\n",
      "FOLD: 4, EPOCH: 18, train_loss: nan\n",
      "FOLD: 4, EPOCH: 18, valid_loss: nan 3.13 seconds\n",
      "FOLD: 4, EPOCH: 19, train_loss: nan\n",
      "FOLD: 4, EPOCH: 19, valid_loss: nan 3.15 seconds\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.47591776032076805\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.024967418164014817 2.99 seconds\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.021140346126187416\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019358756616711617 3.10 seconds\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.01877087041684965\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.017880627289414405 3.11 seconds\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.017802941574886138\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.017601369693875313 3.12 seconds\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.017346644875447768\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.017349202893674375 3.17 seconds\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.017304836753375675\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.01744316179305315 3.12 seconds\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.01737315932504174\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.017425005175173282 3.12 seconds\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.017432384820160816\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.017268714532256126 3.03 seconds\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.01739380378149399\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.01759983729571104 2.96 seconds\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.017460874750652687\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.01726033177226782 3.10 seconds\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.017404224457485334\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.017495599687099458 3.12 seconds\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.017421048216927214\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.01712164133787155 3.17 seconds\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.01727992360841255\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.017212724797427654 3.12 seconds\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.017260244065502875\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.017295928709208964 3.04 seconds\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.017097857375280794\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.017011431083083152 3.00 seconds\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.01701167054778459\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.016941583305597304 3.11 seconds\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.016852749302527125\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.01686703011393547 3.11 seconds\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.016705051216543938\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.016642254889011384 3.12 seconds\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.016417606150870828\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.016554189175367356 3.19 seconds\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.016194547026031684\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.01642689645290375 3.13 seconds\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.015919217054231636\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.01627575173974037 3.11 seconds\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.015597135500133443\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.016154288314282894 3.10 seconds\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.015352316783601735\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.016068076007068156 3.12 seconds\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.015156219802087261\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.016060708649456502 3.11 seconds\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.015053845435178199\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.016068069897592067 3.12 seconds\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.4751765122573797\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.0249980466067791 3.04 seconds\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.02082701388518421\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.020928566306829453 3.12 seconds\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.018767962960817782\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.017898982912302016 3.12 seconds\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.017872505485504665\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.017547483295202254 3.05 seconds\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.017344793475860237\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017997388131916522 3.14 seconds\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.01734482703515056\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01737962704151869 3.10 seconds\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.01734164501001843\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.01729775547981262 3.12 seconds\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.017393304884028273\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.017390238232910634 3.17 seconds\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.017433404878136657\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.01750787753611803 3.11 seconds\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.017406837913353426\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.01734180059283972 3.10 seconds\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.017362120605650403\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.017190183848142623 3.06 seconds\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.017345775774090876\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.01727083873003721 3.17 seconds\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.01731694672180682\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.017134505808353424 3.12 seconds\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.01727803357477699\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.01698207050561905 3.12 seconds\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.017120045964561757\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.01696745652705431 3.16 seconds\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.01702471816798254\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.016822660081088542 2.95 seconds\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.016844439960154545\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.016708666868507863 3.04 seconds\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.016701501851179162\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.01660022221505642 3.07 seconds\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.016447050085126542\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.01645607028156519 3.19 seconds\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.016193134247699158\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.016289572305977343 3.11 seconds\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.015934165586166237\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.016138024888932706 3.03 seconds\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.015661295446358164\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.016081223860383034 3.12 seconds\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.015364336584802388\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.015974093191325665 3.16 seconds\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.015186346110691425\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.01593198426067829 3.11 seconds\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.015100827054152277\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.01593522518873215 3.11 seconds\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.47284523136660356\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.024917244389653207 2.96 seconds\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.021050746964455462\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.018566481992602347 2.99 seconds\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.018568953486526905\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01784061476588249 2.87 seconds\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01778742558240485\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.01750260289758444 3.01 seconds\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01733766887717101\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017390689328312874 3.14 seconds\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017363459473716564\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01733318615704775 3.10 seconds\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017404426567155084\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01753857631236315 3.11 seconds\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01749031212130169\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017334493026137352 3.17 seconds\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01748992268908389\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01754360746592283 2.97 seconds\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.01744877827056006\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017595342099666594 3.11 seconds\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017492790218620075\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01739321932196617 3.01 seconds\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017392956271615564\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017251547388732434 3.16 seconds\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017337583759356113\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01718951843678951 3.12 seconds\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01724082946802686\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017094537392258646 3.12 seconds\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017196558593284516\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01697477463632822 2.99 seconds\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017005710799221686\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016825115866959096 3.12 seconds\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01693027331588828\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01671687141060829 3.09 seconds\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.016718764871764345\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016594713032245637 3.12 seconds\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.016480897078100517\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016509053893387318 3.18 seconds\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01625944344567604\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016366040483117104 3.12 seconds\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01605181501810851\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016161759197711945 3.12 seconds\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01575504057742909\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.01607774890959263 3.14 seconds\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.015482949156339477\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016037774123251438 3.15 seconds\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01530668749569022\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016015258505940436 3.11 seconds\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015216591096400809\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01597733911126852 3.12 seconds\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.4739938643412525\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.024195725843310357 3.10 seconds\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02092291408402174\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.019193971529603004 3.06 seconds\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.0187703447707859\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018213847130537034 2.91 seconds\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.017877301872790265\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017613252252340318 3.05 seconds\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.01743279307523147\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017341968975961207 3.07 seconds\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.01736981065652403\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017450628541409968 3.11 seconds\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017431048270897802\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01758220054209232 3.10 seconds\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01744971870362353\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017395921796560288 3.12 seconds\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01747516550275744\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017390470094978808 3.02 seconds\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01752242500431278\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017546700574457647 2.96 seconds\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017507109037112622\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01732225090265274 3.10 seconds\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01743676711735474\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017337852120399476 3.17 seconds\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017365551636028452\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01701989393681288 3.13 seconds\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017345661550861636\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01711204119026661 3.13 seconds\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01725165821535855\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017042032927274704 3.13 seconds\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01706996992813284\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01684875950217247 3.13 seconds\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01699300639356683\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01683377265930176 3.10 seconds\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.016718780983011335\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01661254372447729 3.14 seconds\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.016509899546449283\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016548140943050384 3.18 seconds\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016311724606876066\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01633424710482359 3.13 seconds\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.016021168005152218\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016200144477188587 3.09 seconds\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.015742757560393842\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01604182902723551 3.05 seconds\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.015502920291912393\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01597181908786297 3.19 seconds\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.015335343461357006\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.015938984416425227 3.11 seconds\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.015240515740651663\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.015941251441836356 3.07 seconds\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.47427122942393735\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.027613469362258912 3.03 seconds\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.020805352120375147\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019348770007491113 3.17 seconds\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.018701477394420272\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018215063512325286 3.07 seconds\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.017811737960952076\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017370087802410127 3.12 seconds\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.017488205235223382\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017305678576231002 3.13 seconds\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017377301429708798\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017466103211045265 3.13 seconds\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017420696031276873\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017265068888664244 3.10 seconds\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017421515176997703\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01733987472951412 3.12 seconds\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017475192872237186\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01746166281402111 3.16 seconds\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017462075301477697\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01731897421181202 3.12 seconds\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01749479186524745\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01720899447798729 3.11 seconds\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017415457969011904\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017124877721071245 3.16 seconds\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017325845185895354\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017187302708625795 3.12 seconds\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017297291228560364\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017074348963797094 3.12 seconds\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01724734866269389\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016886552348732948 3.11 seconds\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017039238728684226\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016954021751880644 3.17 seconds\n",
      "FOLD: 2, EPOCH: 16, train_loss: nan\n",
      "FOLD: 2, EPOCH: 16, valid_loss: nan 3.08 seconds\n",
      "FOLD: 2, EPOCH: 17, train_loss: nan\n",
      "FOLD: 2, EPOCH: 17, valid_loss: nan 3.11 seconds\n",
      "FOLD: 2, EPOCH: 18, train_loss: nan\n",
      "FOLD: 2, EPOCH: 18, valid_loss: nan 3.12 seconds\n",
      "FOLD: 2, EPOCH: 19, train_loss: nan\n",
      "FOLD: 2, EPOCH: 19, valid_loss: nan 3.18 seconds\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.47393831326847985\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.023709094896912575 3.03 seconds\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02079853639766878\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.018850632160902023 3.14 seconds\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.018756485803901744\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018278443217277528 3.18 seconds\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.017834213435599187\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01771418370306492 3.12 seconds\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.017446503011497104\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017456995993852614 3.12 seconds\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017447058447212182\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017453979924321173 3.13 seconds\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017353035249829698\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017488655149936676 3.10 seconds\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01743312626696971\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017703353613615035 3.08 seconds\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01744788530327025\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017767762020230293 3.14 seconds\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01755277327813056\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01745113231241703 3.11 seconds\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017471531393373905\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017379781752824782 3.04 seconds\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017400182403472006\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017442756369709968 2.92 seconds\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017336053146543552\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01722903735935688 3.10 seconds\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017235233651182683\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01721556693315506 3.16 seconds\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017134264073505694\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017101649641990662 2.98 seconds\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017058597586187375\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01710671905428171 3.04 seconds\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01687754505649716\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016906189136207103 3.12 seconds\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.016647450150731876\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016779372952878475 3.19 seconds\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.016441326620069897\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016703012846410275 3.13 seconds\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.0161805476448467\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016418631300330163 3.13 seconds\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.015928552543022195\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016391549296677112 3.15 seconds\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01567638602715974\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01620532900094986 3.11 seconds\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.015361446963281048\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01609994798898697 3.10 seconds\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.015149000081784872\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016076817326247692 3.13 seconds\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015061731367897825\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016080814786255358 3.18 seconds\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.4736808765628914\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.024260378181934356 3.00 seconds\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.020812134733613655\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.018640181273221968 3.13 seconds\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.018760278827327045\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.017813506983220578 3.17 seconds\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.0177685804284957\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017551986053586006 3.13 seconds\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01742805557034048\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017371007166802885 3.10 seconds\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.01744510086418009\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017362605184316635 3.14 seconds\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017457881448220233\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017404283210635186 3.21 seconds\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017458015926131585\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017092609666287898 3.12 seconds\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017556986233004095\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017042110934853555 3.10 seconds\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017504870650820993\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017273784391582014 3.13 seconds\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017510789123420814\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017047071568667888 3.18 seconds\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017433254073570374\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017294096797704696 3.09 seconds\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017442242989988147\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017099801898002625 3.05 seconds\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01735426418381889\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01711205642670393 3.17 seconds\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01722919822474118\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.016748365201056003 3.12 seconds\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017051521980134\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01683875698596239 3.07 seconds\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01691927950271741\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01657556399703026 3.13 seconds\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.016749447471379828\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01652248118072748 3.19 seconds\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.016508507352246314\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01633379340171814 3.13 seconds\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01628259559269665\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01621247850358486 3.12 seconds\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016018878972652008\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016050172969698906 3.17 seconds\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01572368370026958\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.015903128236532213 3.13 seconds\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01548400653057358\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01584041219204664 3.12 seconds\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.015321501625739798\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.015782587490975858 3.15 seconds\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01521342853400983\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.015772792771458627 3.06 seconds\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.47321931414660956\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.02447280503809452 2.54 seconds\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.020858913888128435\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.01936873182654381 3.09 seconds\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.018725134780769852\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.01809588719159365 3.07 seconds\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.017901665030592154\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.017472110092639923 3.18 seconds\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.017401751872076064\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.017412644736468794 3.12 seconds\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.017413583894570667\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.017307098656892776 3.12 seconds\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.017432791681415368\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.01766437716782093 3.18 seconds\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.01739348400206793\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.01777506813406944 3.09 seconds\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.017505526542663574\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.01742778640240431 3.11 seconds\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.017501290767219197\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.017300203293561935 3.11 seconds\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.01743018202052838\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.017329332455992698 3.11 seconds\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.017405519509041796\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.017311880476772786 3.11 seconds\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.01737498878469678\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.017301003001630306 3.11 seconds\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.01723525159973271\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.0171391524001956 3.18 seconds\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.017165515134681245\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.017059115581214427 3.13 seconds\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.017001244207831466\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.017083742134273053 3.13 seconds\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.01686743190702127\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.016837873347103596 3.13 seconds\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.016720049881509373\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.0168104238063097 3.14 seconds\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.016447548412394767\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.016672310270369053 3.12 seconds\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.016228617118278735\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.01645602397620678 3.13 seconds\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.01593154569973751\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.016335846818983556 3.13 seconds\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.015687784002650352\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.01629945769906044 3.13 seconds\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.015410606248849103\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.016118235774338244 3.13 seconds\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.015219044795601952\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.016106033772230147 3.09 seconds\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.015089100987023237\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.016141300797462465 3.12 seconds\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.475144865156031\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.023819450959563254 3.02 seconds\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.020860205448809125\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.020100611671805383 3.11 seconds\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.0186856140059476\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.017921859957277776 3.10 seconds\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.017829312917580005\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.017525375597178938 3.17 seconds\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.01743739572841497\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017403540164232255 3.11 seconds\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.017353211206441024\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01726409573107958 3.00 seconds\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.01735517333838202\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.017325753942131997 3.18 seconds\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.017418991812333768\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.017341128513216973 3.11 seconds\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.017441945600317043\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.01740181487053633 3.09 seconds\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.017400662851881007\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.01754479978233576 2.98 seconds\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.017405273424474156\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.017420252934098244 3.11 seconds\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.017400991139920795\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.01710483804345131 3.11 seconds\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.017353365349830414\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.017249773368239404 3.06 seconds\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.017245980625858113\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.017170054391026496 3.08 seconds\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.01723500926579748\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.016973091252148152 3.18 seconds\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.0170169055563252\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.01698612719774246 3.09 seconds\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.016867415979504585\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.016776595562696457 3.06 seconds\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.01673146091452261\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.01665292143821716 3.17 seconds\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.01650164675499712\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.016510904878377915 3.13 seconds\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.0162659315392375\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.016302709430456162 3.12 seconds\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.015997192176172927\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.016155941039323808 3.08 seconds\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.015691950347046464\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.01608883686363697 3.14 seconds\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.015400177228967754\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.015943946577608586 3.12 seconds\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.015202507414684003\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.015930750370025636 3.01 seconds\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.015119796130983602\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.015915252417325974 3.06 seconds\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [1903, 1881]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014745746816591205\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "#sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
